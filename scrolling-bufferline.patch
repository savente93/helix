diff --git a/book/src/command-line 2.md b/book/src/command-line 2.md
deleted file mode 100644
index 7bf32bbda..000000000
--- a/book/src/command-line 2.md	
+++ /dev/null
@@ -1,82 +0,0 @@
-# Command line
-
-- [Quoting](#quoting)
-- [Flags](#flags)
-- [Expansions](#expansions)
-- [Exceptions](#exceptions)
-
-The command line is used for executing [typable commands](./commands.md#typable-commands) like `:write` or `:quit`. Press `:` to activate the command line.
-
-Typable commands optionally accept arguments. `:write` for example accepts an optional path to write the file contents. The command line also supports a quoting syntax for arguments, flags to modify command behaviors, and _expansions_ - a way to insert values from the editor. Most commands support these features but some have custom parsing rules (see the [exceptions](#exceptions) below).
-
-## Quoting
-
-By default, command arguments are split on tabs and space characters. `:open README.md CHANGELOG.md` for example should open two files, `README.md` and `CHANGELOG.md`. Arguments that contain spaces can be surrounded in single quotes (`'`) or backticks (`` ` ``) to prevent the space from separating the argument, like `:open 'a b.txt'`.
-
-Double quotes may be used the same way, but double quotes _expand_ their inner content. `:echo "%{cursor_line}"` for example may print `1` because of the expansion for the `cursor_line` variable. `:echo '%{cursor_line}'` though prints `%{cursor_line}` literally: content within single quotes or backticks is interpreted as-is.
-
-On Unix systems the backslash character may be used to escape certain characters depending on where it is used. Within an argument which isn't surround in quotes, the backslash can be used to escape the space or tab characters: `:open a\ b.txt` is equivalent to `:open 'a b.txt'`. The backslash may also be used to escape quote characters (`'`, `` ` ``, `"`) or the percent token (`%`) when used at the beginning of an argument. `:echo \%%sh{foo}` for example prints `%sh{foo}` instead of invoking a `foo` shell command and `:echo \"quote` prints `"quote`. The backslash character is treated literally in any other situation on Unix systems and always on Windows: `:echo \n` always prints `\n`.
-
-## Flags
-
-Command flags are optional switches that can be used to alter the behavior of a command. For example the `:sort` command accepts an optional `--reverse` (or `-r` for short) flag which causes the sort command to reverse the sorting direction. Typing the `-` character shows completions for the current command's flags, if any.
-
-The `--` flag specifies the end of flags. All arguments after `--` are treated as positional arguments: `:open -- -a.txt` opens a file called `-a.txt`.
-
-## Expansions
-
-Expansions are patterns that Helix recognizes and replaces within the command line. Helix recognizes anything starting with a percent token (`%`) as an expansion, for example `%sh{echo hi!}`. Expansions are particularly useful when used in commands like `:echo` or `:noop` for executing simple scripts. For example:
-
-```toml
-[keys.normal]
-# Print the current line's git blame information to the statusline.
-space.B = ":echo %sh{git blame -L %{cursor_line},+1 %{buffer_name}}"
-```
-
-Expansions take the form `%[<kind>]<open><contents><close>`. In `%sh{echo hi!}`, for example, the kind is `sh` - the shell expansion - and the contents are "echo hi!", with `{` and `}` acting as opening and closing delimiters. The following open/close characters are recognized as expansion delimiter pairs: `(`/`)`, `[`/`]`, `{`/`}` and `<`/`>`. Plus the single characters `'`, `"` or `|` may be used instead: `%{cursor_line}` is equivalent to `%<cursor_line>`, `%[cursor_line]` or `%|cursor_line|`.
-
-To escape a percent character instead of treating it as an expansion, use two percent characters consecutively. To execute a shell command like `date -u +'%Y-%m-%d'`, double the percent characters: `:echo %sh{date -u +'%%Y-%%m-%%d'}`.
-
-When no `<kind>` is provided, Helix will expand a **variable**. For example `%{cursor_line}` can be used as in argument to insert the line number. `:echo %{cursor_line}` for instance may print `1` to the statusline.
-
-The following variables are supported:
-
-| Name | Description |
-|---   |---          |
-| `cursor_line` | The line number of the primary cursor in the currently focused document, starting at 1. |
-| `cursor_column` | The column number of the primary cursor in the currently focused document, starting at 1. This is counted as the number of grapheme clusters from the start of the line rather than bytes or codepoints. |
-| `buffer_name` | The relative path of the currently focused document. `[scratch]` is expanded instead for scratch buffers. |
-| `line_ending` | A string containing the line ending of the currently focused document. For example on Unix systems this is usually a line-feed character (`\n`) but on Windows systems this may be a carriage-return plus a line-feed (`\r\n`). The line ending kind of the currently focused document can be inspected with the `:line-ending` command. |
-
-Aside from editor variables, the following expansions may be used:
-
-* Unicode `%u{..}`. The contents may contain up to six hexadecimal numbers corresponding to a Unicode codepoint value. For example `:echo %u{25CF}` prints `●` to the statusline.
-* Shell `%sh{..}`. The contents are passed to the configured shell command. For example `:echo %sh{echo "20 * 5" | bc}` may print `100` on the statusline on when using a shell with `echo` and the `bc` calculator installed. Shell expansions are evaluated recursively. `%sh{echo '%{buffer_name}:%{cursor_line}'}` for example executes a command like `echo 'README.md:1'`: the variables within the `%sh{..}` expansion are evaluated before executing the shell command.
-
-As mentioned above, double quotes can be used to surround arguments containing spaces but also support expansions within the quoted content unlike singe quotes or backticks. For example `:echo "circle: %u{25CF}"` prints `circle: ●` to the statusline while `:echo 'circle: %u{25CF}'` prints `circle: %u{25CF}`.
-
-Note that expansions are only evaluated once the Enter key is pressed in command mode.
-
-## Exceptions
-
-The following commands support expansions but otherwise pass the given argument directly to the shell program without interpreting quotes:
-
-* `:insert-output`
-* `:append-output`
-* `:pipe`
-* `:pipe-to`
-* `:run-shell-command`
-
-For example executing `:sh echo "%{buffer_name}:%{cursor_column}"` would pass text like `echo "README.md:1"` as an argument to the shell program: the expansions are evaluated but not the quotes. As mentioned above, percent characters can be used in shell commands by doubling the percent character. To insert the output of a command like `date -u +'%Y-%m-%d'` use `:insert-output date -u +'%%Y-%%m-%%d'`.
-
-The `:set-option` and `:toggle-option` commands use regular parsing for the first argument - the config option name - and parse the rest depending on the config option's type. `:set-option` interprets the second argument as a string for string config options and parses everything else as JSON.
-
-`:toggle-option`'s behavior depends on the JSON type of the config option supplied as the first argument:
-
-* Booleans: only the config option name should be provided. For example `:toggle-option auto-format` will flip the `auto-format` option.
-* Strings: the rest of the command line is parsed with regular quoting rules. For example `:toggle-option indent-heuristic hybrid tree-sitter simple` cycles through "hybrid", "tree-sitter" and "simple" values on each invocation of the command.
-* Numbers, arrays and objects: the rest of the command line is parsed as a stream of JSON values. For example `:toggle-option rulers [81] [51, 73]` cycles through `[81]` and `[51, 73]`.
-
-When providing multiple values to `:toggle-option` there should be no duplicates. `:toggle-option indent-heuristic hybrid simple tree-sitter simple` for example would only toggle between "hybrid" and "tree-sitter" values.
-
-`:lsp-workspace-command` works similarly to `:toggle-option`. The first argument (if present) is parsed according to normal rules. The rest of the line is parsed as JSON values. Unlike `:toggle-option`, string arguments for a command must be quoted. For example `:lsp-workspace-command lsp.Command "foo" "bar"`.
diff --git a/book/src/themes.md b/book/src/themes.md
index 3cd10ff65..dc377db17 100644
--- a/book/src/themes.md
+++ b/book/src/themes.md
@@ -294,7 +294,6 @@ #### Interface
 | `ui.bufferline`                   | Style for the buffer line                                                                      |
 | `ui.bufferline.active`            | Style for the active buffer in buffer line                                                     |
 | `ui.bufferline.background`        | Style for bufferline background                                                                |
-| `ui.bufferline.marker`            | Style for bufferline underflow and overflow markers                                            |
 | `ui.popup`                        | Documentation popups (e.g. Space + k)                                                          |
 | `ui.popup.info`                   | Prompt for multiple key options                                                                |
 | `ui.picker.header`                | Header row area in pickers with multiple columns                                               |
diff --git a/helix-core/src/command_line 2.rs b/helix-core/src/command_line 2.rs
deleted file mode 100644
index 960b247df..000000000
--- a/helix-core/src/command_line 2.rs	
+++ /dev/null
@@ -1,1270 +0,0 @@
-//! Types and parsing code for command mode (`:`) input.
-//!
-//! Command line parsing is done in steps:
-//!
-//! * The `Tokenizer` iterator returns `Token`s from the command line input naively - without
-//!   accounting for a command's signature.
-//! * When executing a command (pressing `<ret>` in command mode), tokens are expanded with
-//!   information from the editor like the current cursor line or column. Otherwise the tokens
-//!   are unwrapped to their inner content.
-//! * `Args` interprets the contents (potentially expanded) as flags or positional arguments.
-//!   When executing a command, `Args` performs validations like checking the number of positional
-//!   arguments supplied and whether duplicate or unknown flags were supplied.
-//!
-//! `Args` is the interface used by typable command implementations. `Args` may be treated as a
-//! slice of `Cow<str>` or `&str` to access positional arguments, for example `for arg in args`
-//! iterates over positional args (never flags) and `&args[0]` always corresponds to the first
-//! positional. Use `Args::has_flag` and `Args::get_flag` to read any specified flags.
-//!
-//! `Args` and `Tokenizer` are intertwined. `Args` may ask the `Tokenizer` for the rest of the
-//! command line as a single token after the configured number of positionals has been reached
-//! (according to `raw_after`). This is used for the custom parsing in `:set-option` and
-//! `:toggle-option` for example. Outside of executing commands, the `Tokenizer` can be used
-//! directly to interpret a string according to the regular tokenization rules.
-//!
-//! This module also defines structs for configuring the parsing of the command line for a
-//! command. See `Flag` and `Signature`.
-
-use std::{borrow::Cow, collections::HashMap, error::Error, fmt, ops, slice, vec};
-
-/// Splits a command line into the command and arguments parts.
-///
-/// The third tuple member describes whether the command part is finished. When this boolean is
-/// true the completion code for the command line should complete command names, otherwise
-/// command arguments.
-pub fn split(line: &str) -> (&str, &str, bool) {
-    const SEPARATOR_PATTERN: [char; 2] = [' ', '\t'];
-
-    let (command, rest) = line.split_once(SEPARATOR_PATTERN).unwrap_or((line, ""));
-
-    let complete_command =
-        command.is_empty() || (rest.trim().is_empty() && !line.ends_with(SEPARATOR_PATTERN));
-
-    (command, rest, complete_command)
-}
-
-/// A Unix-like flag that a command may accept.
-///
-/// For example the `:sort` command accepts a `--reverse` (or `-r` for shorthand) boolean flag
-/// which controls the direction of sorting. Flags may accept an argument by setting the
-/// `completions` field to `Some`.
-#[derive(Debug, Clone, Copy)]
-pub struct Flag {
-    /// The name of the flag.
-    ///
-    /// This value is also used to construct the "longhand" version of the flag. For example a
-    /// flag with a name "reverse" has a longhand `--reverse`.
-    ///
-    /// This value should be supplied when reading a flag out of the [Args] with [Args::get_flag]
-    /// and [Args::has_flag]. The `:sort` command implementation for example should ask for
-    /// `args.has_flag("reverse")`.
-    pub name: &'static str,
-    /// The character that can be used as a shorthand for the flag, optionally.
-    ///
-    /// For example a flag like "reverse" mentioned above might take an alias `Some('r')` to
-    /// allow specifying the flag as `-r`.
-    pub alias: Option<char>,
-    pub doc: &'static str,
-    /// The completion values to use when specifying an argument for a flag.
-    ///
-    /// This should be set to `None` for boolean flags and `Some(&["foo", "bar", "baz"])` for
-    /// example for flags which accept options, with the strings corresponding to values that
-    /// should be shown in completion.
-    pub completions: Option<&'static [&'static str]>,
-}
-
-impl Flag {
-    // This allows defining flags with the `..Flag::DEFAULT` shorthand. The `name` and `doc`
-    // fields should always be overwritten.
-    pub const DEFAULT: Self = Self {
-        name: "",
-        doc: "",
-        alias: None,
-        completions: None,
-    };
-}
-
-/// A description of how a command's input should be handled.
-///
-/// Each typable command defines a signature (with the help of `Signature::DEFAULT`) at least to
-/// declare how many positional arguments it accepts. Command flags are also declared in this
-/// struct. The `raw_after` option may be set optionally to avoid evaluating quotes in parts of
-/// the command line (useful for shell commands for example).
-#[derive(Debug, Clone, Copy)]
-#[allow(clippy::manual_non_exhaustive)]
-pub struct Signature {
-    /// The minimum and (optionally) maximum number of positional arguments a command may take.
-    ///
-    /// For example accepting exactly one positional can be specified with `(1, Some(1))` while
-    /// accepting zero-or-more positionals can be specified as `(0, None)`.
-    ///
-    /// The number of positionals is checked when hitting `<ret>` in command mode. If the actual
-    /// number of positionals is outside the declared range then the command is not executed and
-    /// an error is shown instead. For example `:write` accepts zero or one positional arguments
-    /// (`(0, Some(1))`). A command line like `:write a.txt b.txt` is outside the declared range
-    /// and is not accepted.
-    pub positionals: (usize, Option<usize>),
-    /// The number of **positional** arguments for the parser to read with normal quoting rules.
-    ///
-    /// Once the number has been exceeded then the tokenizer returns the rest of the input as a
-    /// `TokenKind::Expand` token (see `Tokenizer::rest`), meaning that quoting rules do not apply
-    /// and none of the remaining text may be treated as a flag.
-    ///
-    /// If this is set to `None` then the entire command line is parsed with normal quoting and
-    /// flag rules.
-    ///
-    /// A good example use-case for this option is `:toggle-option` which sets `Some(1)`.
-    /// Everything up to the first positional argument is interpreted according to normal rules
-    /// and the rest of the input is parsed "raw". This allows `:toggle-option` to perform custom
-    /// parsing on the rest of the input - namely parsing complicated values as a JSON stream.
-    /// `:toggle-option` could accept a flag in the future. If so, the flag would need to come
-    /// before the first positional argument.
-    ///
-    /// Consider these lines for `:toggle-option` which sets `Some(1)`:
-    ///
-    /// * `:toggle foo` has one positional "foo" and no flags.
-    /// * `:toggle foo bar` has two positionals. Expansions for `bar` are evaluated but quotes
-    ///   and anything that looks like a flag are treated literally.
-    /// * `:toggle foo --bar` has two positionals: `["foo", "--bar"]`. `--bar` is not considered
-    ///   to be a flag because it comes after the first positional.
-    /// * `:toggle --bar foo` has one positional "foo" and one flag "--bar".
-    /// * `:toggle --bar foo --baz` has two positionals `["foo", "--baz"]` and one flag "--bar".
-    pub raw_after: Option<u8>,
-    /// A set of flags that a command may accept.
-    ///
-    /// See the `Flag` struct for more info.
-    pub flags: &'static [Flag],
-    /// Do not set this field. Use `..Signature::DEFAULT` to construct a `Signature` instead.
-    // This field allows adding new fields later with minimal code changes. This works like a
-    // `#[non_exhaustive]` annotation except that it supports the `..Signature::DEFAULT`
-    // shorthand.
-    pub _dummy: (),
-}
-
-impl Signature {
-    // This allows defining signatures with the `..Signature::DEFAULT` shorthand. The
-    // `positionals` field should always be overwritten.
-    pub const DEFAULT: Self = Self {
-        positionals: (0, None),
-        raw_after: None,
-        flags: &[],
-        _dummy: (),
-    };
-
-    fn check_positional_count(&self, actual: usize) -> Result<(), ParseArgsError<'static>> {
-        let (min, max) = self.positionals;
-        if min <= actual && max.unwrap_or(usize::MAX) >= actual {
-            Ok(())
-        } else {
-            Err(ParseArgsError::WrongPositionalCount { min, max, actual })
-        }
-    }
-}
-
-#[derive(Debug, PartialEq, Eq)]
-pub enum ParseArgsError<'a> {
-    WrongPositionalCount {
-        min: usize,
-        max: Option<usize>,
-        actual: usize,
-    },
-    UnterminatedToken {
-        token: Token<'a>,
-    },
-    DuplicatedFlag {
-        flag: &'static str,
-    },
-    UnknownFlag {
-        text: Cow<'a, str>,
-    },
-    FlagMissingArgument {
-        flag: &'static str,
-    },
-    MissingExpansionDelimiter {
-        expansion: &'a str,
-    },
-    UnknownExpansion {
-        kind: &'a str,
-    },
-}
-
-impl fmt::Display for ParseArgsError<'_> {
-    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
-        match self {
-            Self::WrongPositionalCount { min, max, actual } => {
-                write!(f, "expected ")?;
-                let maybe_plural = |n| if n == 1 { "" } else { "s" };
-                match (min, max) {
-                    (0, Some(0)) => write!(f, "no arguments")?,
-                    (min, Some(max)) if min == max => {
-                        write!(f, "exactly {min} argument{}", maybe_plural(*min))?
-                    }
-                    (min, _) if actual < min => {
-                        write!(f, "at least {min} argument{}", maybe_plural(*min))?
-                    }
-                    (_, Some(max)) if actual > max => {
-                        write!(f, "at most {max} argument{}", maybe_plural(*max))?
-                    }
-                    // `actual` must be either less than `min` or greater than `max` for this type
-                    // to be constructed.
-                    _ => unreachable!(),
-                }
-
-                write!(f, ", got {actual}")
-            }
-            Self::UnterminatedToken { token } => {
-                write!(f, "unterminated token {}", token.content)
-            }
-            Self::DuplicatedFlag { flag } => {
-                write!(f, "flag '--{flag}' specified more than once")
-            }
-            Self::UnknownFlag { text } => write!(f, "unknown flag '{text}'"),
-            Self::FlagMissingArgument { flag } => {
-                write!(f, "flag '--{flag}' missing an argument")
-            }
-            Self::MissingExpansionDelimiter { expansion } => {
-                if expansion.is_empty() {
-                    write!(f, "'%' was not properly escaped. Please use '%%'")
-                } else {
-                    write!(f, "missing a string delimiter after '%{expansion}'")
-                }
-            }
-            Self::UnknownExpansion { kind } => {
-                write!(f, "unknown expansion '{kind}'")
-            }
-        }
-    }
-}
-
-impl Error for ParseArgsError<'_> {}
-
-/// The kind of expansion to use on the token's content.
-#[derive(Debug, Clone, Copy, PartialEq, Eq)]
-pub enum ExpansionKind {
-    /// Expand variables from the editor's state.
-    ///
-    /// For example `%{cursor_line}`.
-    Variable,
-    /// Treat the token contents as hexadecimal corresponding to a Unicode codepoint value.
-    ///
-    /// For example `%u{25CF}`.
-    Unicode,
-    /// Run the token's contents via the configured shell program.
-    ///
-    /// For example `%sh{echo hello}`.
-    Shell,
-}
-
-impl ExpansionKind {
-    pub const VARIANTS: &'static [Self] = &[Self::Variable, Self::Unicode, Self::Shell];
-
-    pub const fn as_str(&self) -> &'static str {
-        match self {
-            Self::Variable => "",
-            Self::Unicode => "u",
-            Self::Shell => "sh",
-        }
-    }
-
-    pub fn from_kind(name: &str) -> Option<Self> {
-        match name {
-            "" => Some(Self::Variable),
-            "u" => Some(Self::Unicode),
-            "sh" => Some(Self::Shell),
-            _ => None,
-        }
-    }
-}
-
-#[derive(Debug, Clone, Copy, PartialEq, Eq)]
-pub enum Quote {
-    Single,
-    Backtick,
-}
-
-impl Quote {
-    pub const fn char(&self) -> char {
-        match self {
-            Self::Single => '\'',
-            Self::Backtick => '`',
-        }
-    }
-
-    // Quotes can be escaped by doubling them: `'hello '' world'` becomes `hello ' world`.
-    pub const fn escape(&self) -> &'static str {
-        match self {
-            Self::Single => "''",
-            Self::Backtick => "``",
-        }
-    }
-}
-
-/// The type of argument being written.
-///
-/// The token kind decides how an argument in the command line will be expanded upon hitting
-/// `<ret>` in command mode.
-#[derive(Debug, Clone, Copy, PartialEq, Eq)]
-pub enum TokenKind {
-    /// Unquoted text.
-    ///
-    /// For example in `:echo hello world`, "hello" and "world" are raw tokens.
-    Unquoted,
-    /// Quoted text which is interpreted literally.
-    ///
-    /// The purpose of this kind is to avoid splitting arguments on whitespace. For example
-    /// `:open 'a b.txt'` will result in opening a file with a single argument `"a b.txt"`.
-    ///
-    /// Using expansions within single quotes or backticks will result in the expansion text
-    /// being shown literally. For example `:echo '%u{0020}'` will print `"%u{0020}"` to the
-    /// statusline.
-    Quoted(Quote),
-    /// Text within double quote delimiters (`"`).
-    ///
-    /// The inner text of a double quoted argument can be further expanded. For example
-    /// `:echo "line: #%{cursor_line}"` could print `"line: #1"` to the statusline.
-    Expand,
-    /// An expansion / "percent token".
-    ///
-    /// These take the form `%[<kind>]<open><contents><close>`. See `ExpansionKind`.
-    Expansion(ExpansionKind),
-    /// A token kind that exists for the sake of completion.
-    ///
-    /// In input like `%foo` this token contains the text `"%foo"`. The content start is the byte
-    /// after the percent token.
-    ///
-    /// When `Tokenizer` is passed `true` for its `validate` parameter this token cannot be
-    /// returned: inputs that would return this token get a validation error instead.
-    ExpansionKind,
-}
-
-#[derive(Debug, Clone, PartialEq, Eq)]
-pub struct Token<'a> {
-    pub kind: TokenKind,
-    /// The byte index into the input where the token's content starts.
-    ///
-    /// For quoted text this means the byte after the quote. For expansions this means the byte
-    /// after the opening delimiter.
-    pub content_start: usize,
-    /// The inner content of the token.
-    ///
-    /// Usually this content borrows from the input but an owned value may be used in cases of
-    /// escaping. On Unix systems a raw token like `a\ b` has the contents `"a b"`.
-    pub content: Cow<'a, str>,
-    /// Whether the token's opening delimiter is closed.
-    ///
-    /// For example a quote `"foo"` is closed but not `"foo` or an expansion `%sh{..}` is closed
-    /// but not `%sh{echo {}`.
-    pub is_terminated: bool,
-}
-
-impl Token<'_> {
-    pub fn empty_at(content_start: usize) -> Self {
-        Self {
-            kind: TokenKind::Unquoted,
-            content_start,
-            content: Cow::Borrowed(""),
-            is_terminated: false,
-        }
-    }
-}
-
-#[derive(Debug)]
-pub struct Tokenizer<'a> {
-    input: &'a str,
-    /// Whether to return errors in the iterator for failed validations like unterminated strings
-    /// or expansions. When this is set to `false` the iterator will never return `Err`.
-    validate: bool,
-    /// The current byte index of the input being considered.
-    pos: usize,
-}
-
-impl<'a> Tokenizer<'a> {
-    pub fn new(input: &'a str, validate: bool) -> Self {
-        Self {
-            input,
-            validate,
-            pos: 0,
-        }
-    }
-
-    /// Returns the current byte index position of the parser in the input.
-    pub fn pos(&self) -> usize {
-        self.pos
-    }
-
-    /// Returns the rest of the input as a single `TokenKind::Expand` token literally.
-    ///
-    /// Returns `None` if the tokenizer is already at the end of the input or advances the
-    /// tokenizer to the end of the input otherwise. Leading whitespace characters are skipped.
-    /// Quoting is not interpreted.
-    pub fn rest(&mut self) -> Option<Token<'a>> {
-        self.skip_blanks();
-
-        if self.pos == self.input.len() {
-            return None;
-        }
-
-        let content_start = self.pos;
-        self.pos = self.input.len();
-        Some(Token {
-            kind: TokenKind::Expand,
-            content_start,
-            content: Cow::Borrowed(&self.input[content_start..]),
-            is_terminated: false,
-        })
-    }
-
-    fn byte(&self) -> Option<u8> {
-        self.input.as_bytes().get(self.pos).copied()
-    }
-
-    fn peek_byte(&self) -> Option<u8> {
-        self.input.as_bytes().get(self.pos + 1).copied()
-    }
-
-    fn prev_byte(&self) -> Option<u8> {
-        self.pos
-            .checked_sub(1)
-            .map(|idx| self.input.as_bytes()[idx])
-    }
-
-    fn skip_blanks(&mut self) {
-        while let Some(b' ' | b'\t') = self.byte() {
-            self.pos += 1;
-        }
-    }
-
-    fn parse_unquoted(&mut self) -> Cow<'a, str> {
-        // Note that `String::new` starts with no allocation. We only allocate if we see a
-        // backslash escape (on Unix only).
-        let mut escaped = String::new();
-        let mut start = self.pos;
-
-        while let Some(byte) = self.byte() {
-            if matches!(byte, b' ' | b'\t') {
-                if cfg!(unix) && self.prev_byte() == Some(b'\\') {
-                    // Push everything up to but not including the backslash and then this
-                    // whitespace character.
-                    escaped.push_str(&self.input[start..self.pos - 1]);
-                    escaped.push(byte as char);
-                    start = self.pos + 1;
-                } else if escaped.is_empty() {
-                    return Cow::Borrowed(&self.input[start..self.pos]);
-                } else {
-                    break;
-                }
-            }
-
-            self.pos += 1;
-        }
-
-        // Special case for a trailing backslash on Unix: exclude the backslash from the content.
-        // This improves the behavior of completions like `":open a\\"` (trailing backslash).
-        let end = if cfg!(unix) && self.prev_byte() == Some(b'\\') {
-            self.pos - 1
-        } else {
-            self.pos
-        };
-
-        if escaped.is_empty() {
-            assert_eq!(self.pos, self.input.len());
-            Cow::Borrowed(&self.input[start..end])
-        } else {
-            escaped.push_str(&self.input[start..end]);
-            Cow::Owned(escaped)
-        }
-    }
-
-    /// Parses a string quoted by the given grapheme cluster.
-    ///
-    /// The position of the tokenizer is asserted to be immediately after the quote grapheme
-    /// cluster.
-    fn parse_quoted(&mut self, quote: u8) -> (Cow<'a, str>, bool) {
-        assert_eq!(self.byte(), Some(quote));
-        self.pos += 1;
-
-        let mut escaped = String::new();
-        while let Some(offset) = self.input[self.pos..].find(quote as char) {
-            let idx = self.pos + offset;
-            if self.input.as_bytes().get(idx + 1) == Some(&quote) {
-                // Treat two quotes in a row as an escape.
-                escaped.push_str(&self.input[self.pos..idx + 1]);
-                // Advance past the escaped quote.
-                self.pos = idx + 2;
-            } else {
-                // Otherwise this quote string is finished.
-                let quoted = if escaped.is_empty() {
-                    Cow::Borrowed(&self.input[self.pos..idx])
-                } else {
-                    escaped.push_str(&self.input[self.pos..idx]);
-                    Cow::Owned(escaped)
-                };
-                // Advance past the closing quote.
-                self.pos = idx + 1;
-                return (quoted, true);
-            }
-        }
-
-        let quoted = if escaped.is_empty() {
-            Cow::Borrowed(&self.input[self.pos..])
-        } else {
-            escaped.push_str(&self.input[self.pos..]);
-            Cow::Owned(escaped)
-        };
-        self.pos = self.input.len();
-
-        (quoted, false)
-    }
-
-    /// Parses the percent token expansion under the tokenizer's cursor.
-    ///
-    /// This function should only be called when the tokenizer's cursor is on a non-escaped
-    /// percent token.
-    pub fn parse_percent_token(&mut self) -> Option<Result<Token<'a>, ParseArgsError<'a>>> {
-        assert_eq!(self.byte(), Some(b'%'));
-
-        self.pos += 1;
-        let kind_start = self.pos;
-        self.pos += self.input[self.pos..]
-            .bytes()
-            .take_while(|b| b.is_ascii_lowercase())
-            .count();
-        let kind = &self.input[kind_start..self.pos];
-
-        let (open, close) = match self.byte() {
-            // We support a couple of hard-coded chars only to make sure we can provide more
-            // useful errors and avoid weird behavior in case of typos. These should cover
-            // practical cases.
-            Some(b'(') => (b'(', b')'),
-            Some(b'[') => (b'[', b']'),
-            Some(b'{') => (b'{', b'}'),
-            Some(b'<') => (b'<', b'>'),
-            Some(b'\'') => (b'\'', b'\''),
-            Some(b'\"') => (b'\"', b'\"'),
-            Some(b'|') => (b'|', b'|'),
-            Some(_) | None => {
-                return Some(if self.validate {
-                    Err(ParseArgsError::MissingExpansionDelimiter { expansion: kind })
-                } else {
-                    Ok(Token {
-                        kind: TokenKind::ExpansionKind,
-                        content_start: kind_start,
-                        content: Cow::Borrowed(kind),
-                        is_terminated: false,
-                    })
-                });
-            }
-        };
-        // The content start for expansions is the start of the content - after the opening
-        // delimiter grapheme.
-        let content_start = self.pos + 1;
-        let kind = match ExpansionKind::from_kind(kind) {
-            Some(kind) => TokenKind::Expansion(kind),
-            None if self.validate => {
-                return Some(Err(ParseArgsError::UnknownExpansion { kind }));
-            }
-            None => TokenKind::Expand,
-        };
-
-        let (content, is_terminated) = if open == close {
-            self.parse_quoted(open)
-        } else {
-            self.parse_quoted_balanced(open, close)
-        };
-
-        let token = Token {
-            kind,
-            content_start,
-            content,
-            is_terminated,
-        };
-
-        if self.validate && !is_terminated {
-            return Some(Err(ParseArgsError::UnterminatedToken { token }));
-        }
-
-        Some(Ok(token))
-    }
-
-    /// Parse the next string under the cursor given an open and closing pair.
-    ///
-    /// The open and closing pair are different ASCII characters. The cursor is asserted to be
-    /// immediately after the opening delimiter.
-    ///
-    /// This function parses with nesting support. `%sh{echo {hello}}` for example should consume
-    /// the entire input and not quit after the first '}' character is found.
-    fn parse_quoted_balanced(&mut self, open: u8, close: u8) -> (Cow<'a, str>, bool) {
-        assert_eq!(self.byte(), Some(open));
-        self.pos += 1;
-        let start = self.pos;
-        let mut level = 1;
-
-        while let Some(offset) = self.input[self.pos..].find([open as char, close as char]) {
-            let idx = self.pos + offset;
-            // Move past the delimiter.
-            self.pos = idx + 1;
-
-            let byte = self.input.as_bytes()[idx];
-            if byte == open {
-                level += 1;
-            } else if byte == close {
-                level -= 1;
-                if level == 0 {
-                    break;
-                }
-            } else {
-                unreachable!()
-            }
-        }
-
-        let is_terminated = level == 0;
-        let end = if is_terminated {
-            // Exclude the closing delimiter from the token's content.
-            self.pos - 1
-        } else {
-            // When the token is not closed, advance to the end of the input.
-            self.pos = self.input.len();
-            self.pos
-        };
-
-        (Cow::Borrowed(&self.input[start..end]), is_terminated)
-    }
-}
-
-impl<'a> Iterator for Tokenizer<'a> {
-    type Item = Result<Token<'a>, ParseArgsError<'a>>;
-
-    fn next(&mut self) -> Option<Self::Item> {
-        self.skip_blanks();
-
-        let byte = self.byte()?;
-        match byte {
-            b'"' | b'\'' | b'`' => {
-                let content_start = self.pos + 1;
-                let (content, is_terminated) = self.parse_quoted(byte);
-                let token = Token {
-                    kind: match byte {
-                        b'"' => TokenKind::Expand,
-                        b'\'' => TokenKind::Quoted(Quote::Single),
-                        b'`' => TokenKind::Quoted(Quote::Backtick),
-                        _ => unreachable!(),
-                    },
-                    content_start,
-                    content,
-                    is_terminated,
-                };
-
-                Some(if self.validate && !is_terminated {
-                    Err(ParseArgsError::UnterminatedToken { token })
-                } else {
-                    Ok(token)
-                })
-            }
-            b'%' => self.parse_percent_token(),
-            _ => {
-                let content_start = self.pos;
-
-                // Allow backslash escaping on Unix for quotes or expansions
-                if cfg!(unix)
-                    && byte == b'\\'
-                    && matches!(self.peek_byte(), Some(b'"' | b'\'' | b'`' | b'%'))
-                {
-                    self.pos += 1;
-                }
-
-                Some(Ok(Token {
-                    kind: TokenKind::Unquoted,
-                    content_start,
-                    content: self.parse_unquoted(),
-                    is_terminated: false,
-                }))
-            }
-        }
-    }
-}
-
-#[derive(Debug, Default, Clone, Copy)]
-pub enum CompletionState {
-    #[default]
-    Positional,
-    Flag(Option<Flag>),
-    FlagArgument(Flag),
-}
-
-/// A set of arguments provided to a command on the command line.
-///
-/// Regular arguments are called "positional" arguments (or "positionals" for short). Command line
-/// input might also specify "flags" which can modify a command's behavior.
-///
-/// ```rust,ignore
-/// // Say that the command accepts a "bar" flag which doesn't accept an argument itself.
-/// // This input has two positionals, "foo" and "baz" and one flag "--bar".
-/// let args = Args::parse("foo --bar baz", /* .. */);
-/// // `Args` may be treated like a slice to access positionals.
-/// assert_eq!(args.len(), 2);
-/// assert_eq!(&args[0], "foo");
-/// assert_eq!(&args[1], "baz");
-/// // Use `has_flag` or `get_flag` to access flags.
-/// assert!(args.has_flag("bar"));
-/// ```
-///
-/// The `Args` type can be treated mostly the same as a slice when accessing positional arguments.
-/// Common slice methods like `len`, `get`, `first` and `join` only expose positional arguments.
-/// Additionally, common syntax like `for arg in args` or `&args[idx]` is supported for accessing
-/// positional arguments.
-///
-/// To look up flags, use `Args::get_flag` for flags which should accept an argument or
-/// `Args::has_flag` for boolean flags.
-///
-/// The way that `Args` is parsed from the input depends on a command's `Signature`. See the
-/// `Signature` type for more details.
-#[derive(Debug)]
-pub struct Args<'a> {
-    signature: Signature,
-    /// Whether to validate the arguments.
-    /// See the `ParseArgsError` type for the validations.
-    validate: bool,
-    /// Whether args pushed with `Self::push` should be treated as positionals even if they
-    /// start with '-'.
-    only_positionals: bool,
-    state: CompletionState,
-    positionals: Vec<Cow<'a, str>>,
-    flags: HashMap<&'static str, Cow<'a, str>>,
-}
-
-impl Default for Args<'_> {
-    fn default() -> Self {
-        Self {
-            signature: Signature::DEFAULT,
-            validate: Default::default(),
-            only_positionals: Default::default(),
-            state: CompletionState::default(),
-            positionals: Default::default(),
-            flags: Default::default(),
-        }
-    }
-}
-
-impl<'a> Args<'a> {
-    pub fn new(signature: Signature, validate: bool) -> Self {
-        Self {
-            signature,
-            validate,
-            only_positionals: false,
-            positionals: Vec::new(),
-            flags: HashMap::new(),
-            state: CompletionState::default(),
-        }
-    }
-
-    /// Reads the next token out of the given parser.
-    ///
-    /// If the command's signature sets a maximum number of positionals (via `raw_after`) then
-    /// the token may contain the rest of the parser's input.
-    pub fn read_token<'p>(
-        &mut self,
-        parser: &mut Tokenizer<'p>,
-    ) -> Result<Option<Token<'p>>, ParseArgsError<'p>> {
-        if self
-            .signature
-            .raw_after
-            .is_some_and(|max| self.len() >= max as usize)
-        {
-            self.only_positionals = true;
-            Ok(parser.rest())
-        } else {
-            parser.next().transpose()
-        }
-    }
-
-    /// Parses the given command line according to a command's signature.
-    ///
-    /// The `try_map_fn` function can be used to try changing each token before it is considered
-    /// as an argument - this is used for variable expansion.
-    pub fn parse<M>(
-        line: &'a str,
-        signature: Signature,
-        validate: bool,
-        mut try_map_fn: M,
-    ) -> Result<Self, Box<dyn Error + 'a>>
-    where
-        // Note: this is a `FnMut` in case we decide to allow caching expansions in the future.
-        // The `mut` is not currently used.
-        M: FnMut(Token<'a>) -> Result<Cow<'a, str>, Box<dyn Error>>,
-    {
-        let mut tokenizer = Tokenizer::new(line, validate);
-        let mut args = Self::new(signature, validate);
-
-        while let Some(token) = args.read_token(&mut tokenizer)? {
-            let arg = try_map_fn(token)?;
-            args.push(arg)?;
-        }
-
-        args.finish()?;
-
-        Ok(args)
-    }
-
-    /// Adds the given argument token.
-    ///
-    /// Once all arguments have been added, `Self::finish` should be called to perform any
-    /// closing validations.
-    pub fn push(&mut self, arg: Cow<'a, str>) -> Result<(), ParseArgsError<'a>> {
-        if !self.only_positionals && arg == "--" {
-            // "--" marks the end of flags, everything after is a positional even if it starts
-            // with '-'.
-            self.only_positionals = true;
-            self.state = CompletionState::Flag(None);
-        } else if let Some(flag) = self.flag_awaiting_argument() {
-            // If the last token was a flag which accepts an argument, treat this token as a flag
-            // argument.
-            self.flags.insert(flag.name, arg);
-            self.state = CompletionState::FlagArgument(flag);
-        } else if !self.only_positionals && arg.starts_with('-') {
-            // If the token starts with '-' and we are not only accepting positional arguments,
-            // treat this token as a flag.
-            let flag = if let Some(longhand) = arg.strip_prefix("--") {
-                self.signature
-                    .flags
-                    .iter()
-                    .find(|flag| flag.name == longhand)
-            } else {
-                let shorthand = arg.strip_prefix('-').unwrap();
-                self.signature.flags.iter().find(|flag| {
-                    flag.alias
-                        .is_some_and(|ch| shorthand == ch.encode_utf8(&mut [0; 4]))
-                })
-            };
-
-            let Some(flag) = flag else {
-                if self.validate {
-                    return Err(ParseArgsError::UnknownFlag { text: arg });
-                }
-
-                self.positionals.push(arg);
-                self.state = CompletionState::Flag(None);
-                return Ok(());
-            };
-
-            if self.validate && self.flags.contains_key(flag.name) {
-                return Err(ParseArgsError::DuplicatedFlag { flag: flag.name });
-            }
-
-            self.flags.insert(flag.name, Cow::Borrowed(""));
-            self.state = CompletionState::Flag(Some(*flag));
-        } else {
-            // Otherwise this token is a positional argument.
-            self.positionals.push(arg);
-            self.state = CompletionState::Positional;
-        }
-
-        Ok(())
-    }
-
-    /// Performs any validations that must be done after the input args are finished being pushed
-    /// with `Self::push`.
-    fn finish(&self) -> Result<(), ParseArgsError<'a>> {
-        if !self.validate {
-            return Ok(());
-        };
-
-        if let Some(flag) = self.flag_awaiting_argument() {
-            return Err(ParseArgsError::FlagMissingArgument { flag: flag.name });
-        }
-        self.signature
-            .check_positional_count(self.positionals.len())?;
-
-        Ok(())
-    }
-
-    fn flag_awaiting_argument(&self) -> Option<Flag> {
-        match self.state {
-            CompletionState::Flag(flag) => flag.filter(|f| f.completions.is_some()),
-            _ => None,
-        }
-    }
-
-    /// Returns the kind of argument the last token is considered to be.
-    ///
-    /// For example if the last argument in the command line is `--foo` then the argument may be
-    /// considered to be a flag.
-    pub fn completion_state(&self) -> CompletionState {
-        self.state
-    }
-
-    /// Returns the number of positionals supplied in the input.
-    ///
-    /// This number does not account for any flags passed in the input.
-    pub fn len(&self) -> usize {
-        self.positionals.len()
-    }
-
-    /// Checks whether the arguments contain no positionals.
-    ///
-    /// Note that this function returns `true` if there are no positional arguments even if the
-    /// input contained flags.
-    pub fn is_empty(&self) -> bool {
-        self.positionals.is_empty()
-    }
-
-    /// Gets the first positional argument, if one exists.
-    pub fn first(&'a self) -> Option<&'a str> {
-        self.positionals.first().map(AsRef::as_ref)
-    }
-
-    /// Gets the positional argument at the given index, if one exists.
-    pub fn get(&'a self, index: usize) -> Option<&'a str> {
-        self.positionals.get(index).map(AsRef::as_ref)
-    }
-
-    /// Flattens all positional arguments together with the given separator between each
-    /// positional.
-    pub fn join(&self, sep: &str) -> String {
-        self.positionals.join(sep)
-    }
-
-    /// Returns an iterator over all positional arguments.
-    pub fn iter(&self) -> slice::Iter<'_, Cow<'_, str>> {
-        self.positionals.iter()
-    }
-
-    /// Gets the value associated with a flag's long name if the flag was provided.
-    ///
-    /// This function should be preferred over [Self::has_flag] when the flag accepts an argument.
-    pub fn get_flag(&'a self, name: &'static str) -> Option<&'a str> {
-        debug_assert!(
-            self.signature.flags.iter().any(|flag| flag.name == name),
-            "flag '--{name}' does not belong to the command's signature"
-        );
-        debug_assert!(
-            self.signature
-                .flags
-                .iter()
-                .any(|flag| flag.name == name && flag.completions.is_some()),
-            "Args::get_flag was used for '--{name}' but should only be used for flags with arguments, use Args::has_flag instead"
-        );
-
-        self.flags.get(name).map(AsRef::as_ref)
-    }
-
-    /// Checks if a flag was provided in the arguments.
-    ///
-    /// This function should be preferred over [Self::get_flag] for boolean flags - flags that
-    /// either are present or not.
-    pub fn has_flag(&self, name: &'static str) -> bool {
-        debug_assert!(
-            self.signature.flags.iter().any(|flag| flag.name == name),
-            "flag '--{name}' does not belong to the command's signature"
-        );
-        debug_assert!(
-            self.signature
-                .flags
-                .iter()
-                .any(|flag| flag.name == name && flag.completions.is_none()),
-            "Args::has_flag was used for '--{name}' but should only be used for flags without arguments, use Args::get_flag instead"
-        );
-
-        self.flags.contains_key(name)
-    }
-}
-
-// `arg[n]`
-impl ops::Index<usize> for Args<'_> {
-    type Output = str;
-
-    fn index(&self, index: usize) -> &Self::Output {
-        self.positionals[index].as_ref()
-    }
-}
-
-// `for arg in args { .. }`
-impl<'a> IntoIterator for Args<'a> {
-    type Item = Cow<'a, str>;
-    type IntoIter = vec::IntoIter<Cow<'a, str>>;
-
-    fn into_iter(self) -> Self::IntoIter {
-        self.positionals.into_iter()
-    }
-}
-
-// `for arg in &args { .. }`
-impl<'i, 'a> IntoIterator for &'i Args<'a> {
-    type Item = &'i Cow<'a, str>;
-    type IntoIter = slice::Iter<'i, Cow<'a, str>>;
-
-    fn into_iter(self) -> Self::IntoIter {
-        self.positionals.iter()
-    }
-}
-
-#[cfg(test)]
-mod test {
-    use super::*;
-
-    #[track_caller]
-    fn assert_tokens(input: &str, expected: &[&str]) {
-        let actual: Vec<_> = Tokenizer::new(input, true)
-            .map(|arg| arg.unwrap().content)
-            .collect();
-        let actual: Vec<_> = actual.iter().map(|c| c.as_ref()).collect();
-
-        assert_eq!(actual.as_slice(), expected);
-    }
-
-    #[track_caller]
-    fn assert_incomplete_tokens(input: &str, expected: &[&str]) {
-        assert!(
-            Tokenizer::new(input, true).collect::<Result<Vec<_>, _>>().is_err(),
-            "`assert_incomplete_tokens` only accepts input that fails validation, consider using `assert_tokens` instead"
-        );
-
-        let actual: Vec<_> = Tokenizer::new(input, false)
-            .map(|arg| arg.unwrap().content)
-            .collect();
-        let actual: Vec<_> = actual.iter().map(|c| c.as_ref()).collect();
-
-        assert_eq!(actual.as_slice(), expected);
-    }
-
-    #[test]
-    fn tokenize_unquoted() {
-        assert_tokens("", &[]);
-        assert_tokens("hello", &["hello"]);
-        assert_tokens("hello world", &["hello", "world"]);
-        // Any amount of whitespace is considered a separator.
-        assert_tokens("hello\t \tworld", &["hello", "world"]);
-    }
-
-    // This escaping behavior is specific to Unix systems.
-    #[cfg(unix)]
-    #[test]
-    fn tokenize_backslash_unix() {
-        assert_tokens(r#"hello\ world"#, &["hello world"]);
-        assert_tokens(r#"one\ two three"#, &["one two", "three"]);
-        assert_tokens(r#"one two\ three"#, &["one", "two three"]);
-        // Trailing backslash is ignored - this improves completions.
-        assert_tokens(r#"hello\"#, &["hello"]);
-        // The backslash at the start of the double quote makes the quote be treated as raw.
-        // For the backslash before the ending quote the token is already considered raw so the
-        // backslash and quote are treated literally.
-        assert_tokens(
-            r#"echo \"hello        world\""#,
-            &["echo", r#""hello"#, r#"world\""#],
-        );
-    }
-
-    #[test]
-    fn tokenize_backslash() {
-        assert_tokens(r#"\n"#, &["\\n"]);
-        assert_tokens(r#"'\'"#, &["\\"]);
-    }
-
-    #[test]
-    fn tokenize_quoting() {
-        // Using a quote character twice escapes it.
-        assert_tokens(r#"''"#, &[""]);
-        assert_tokens(r#""""#, &[""]);
-        assert_tokens(r#"``"#, &[""]);
-        assert_tokens(r#"echo """#, &["echo", ""]);
-
-        assert_tokens(r#"'hello'"#, &["hello"]);
-        assert_tokens(r#"'hello world'"#, &["hello world"]);
-
-        assert_tokens(r#""hello "" world""#, &["hello \" world"]);
-    }
-
-    #[test]
-    fn tokenize_percent() {
-        // Pair delimiters:
-        assert_tokens(r#"echo %{hello world}"#, &["echo", "hello world"]);
-        assert_tokens(r#"echo %[hello world]"#, &["echo", "hello world"]);
-        assert_tokens(r#"echo %(hello world)"#, &["echo", "hello world"]);
-        assert_tokens(r#"echo %<hello world>"#, &["echo", "hello world"]);
-        assert_tokens(r#"echo %|hello world|"#, &["echo", "hello world"]);
-        assert_tokens(r#"echo %'hello world'"#, &["echo", "hello world"]);
-        assert_tokens(r#"echo %"hello world""#, &["echo", "hello world"]);
-        // When invoking a command, double percents can be used within a string as an escape for
-        // the percent. This is done in the expansion code though, not in the parser here.
-        assert_tokens(r#"echo "%%hello world""#, &["echo", "%%hello world"]);
-        // Different kinds of quotes nested:
-        assert_tokens(
-            r#"echo "%sh{echo 'hello world'}""#,
-            &["echo", r#"%sh{echo 'hello world'}"#],
-        );
-        // Nesting of the expansion delimiter:
-        assert_tokens(r#"echo %{hello {x} world}"#, &["echo", "hello {x} world"]);
-        assert_tokens(
-            r#"echo %{hello {{😎}} world}"#,
-            &["echo", "hello {{😎}} world"],
-        );
-
-        // Balanced nesting:
-        assert_tokens(
-            r#"echo %{hello {}} world}"#,
-            &["echo", "hello {}", "world}"],
-        );
-
-        // Recursive expansions:
-        assert_tokens(
-            r#"echo %sh{echo "%{cursor_line}"}"#,
-            &["echo", r#"echo "%{cursor_line}""#],
-        );
-        // Completion should provide variable names here. (Unbalanced nesting)
-        assert_incomplete_tokens(r#"echo %sh{echo "%{c"#, &["echo", r#"echo "%{c"#]);
-        assert_incomplete_tokens(r#"echo %{hello {{} world}"#, &["echo", "hello {{} world}"]);
-    }
-
-    fn parse_signature<'a>(
-        input: &'a str,
-        signature: Signature,
-    ) -> Result<Args<'a>, Box<dyn std::error::Error + 'a>> {
-        Args::parse(input, signature, true, |token| Ok(token.content))
-    }
-
-    #[test]
-    fn signature_validation_positionals() {
-        let signature = Signature {
-            positionals: (2, Some(3)),
-            ..Signature::DEFAULT
-        };
-
-        assert!(parse_signature("hello world", signature).is_ok());
-        assert!(parse_signature("foo bar baz", signature).is_ok());
-        assert!(parse_signature(r#"a "b c" d"#, signature).is_ok());
-
-        assert!(parse_signature("hello", signature).is_err());
-        assert!(parse_signature("foo bar baz quiz", signature).is_err());
-
-        let signature = Signature {
-            positionals: (1, None),
-            ..Signature::DEFAULT
-        };
-
-        assert!(parse_signature("a", signature).is_ok());
-        assert!(parse_signature("a b", signature).is_ok());
-        assert!(parse_signature(r#"a "b c" d"#, signature).is_ok());
-
-        assert!(parse_signature("", signature).is_err());
-    }
-
-    #[test]
-    fn flags() {
-        let signature = Signature {
-            positionals: (1, Some(2)),
-            flags: &[
-                Flag {
-                    name: "foo",
-                    alias: Some('f'),
-                    doc: "",
-                    completions: None,
-                },
-                Flag {
-                    name: "bar",
-                    alias: Some('b'),
-                    doc: "",
-                    completions: Some(&[]),
-                },
-            ],
-            ..Signature::DEFAULT
-        };
-
-        let args = parse_signature("hello", signature).unwrap();
-        assert_eq!(args.len(), 1);
-        assert_eq!(&args[0], "hello");
-        assert!(!args.has_flag("foo"));
-        assert!(args.get_flag("bar").is_none());
-
-        let args = parse_signature("--bar abcd hello world --foo", signature).unwrap();
-        assert_eq!(args.len(), 2);
-        assert_eq!(&args[0], "hello");
-        assert_eq!(&args[1], "world");
-        assert!(args.has_flag("foo"));
-        assert_eq!(args.get_flag("bar"), Some("abcd"));
-
-        let args = parse_signature("hello -f -b abcd world", signature).unwrap();
-        assert_eq!(args.len(), 2);
-        assert_eq!(&args[0], "hello");
-        assert_eq!(&args[1], "world");
-        assert!(args.has_flag("foo"));
-        assert_eq!(args.get_flag("bar"), Some("abcd"));
-
-        // The signature requires at least one positional.
-        assert!(parse_signature("--foo", signature).is_err());
-        // And at most two.
-        assert!(parse_signature("abc --bar baz def efg", signature).is_err());
-
-        let args = parse_signature(r#"abc -b "xyz 123" def"#, signature).unwrap();
-        assert_eq!(args.len(), 2);
-        assert_eq!(&args[0], "abc");
-        assert_eq!(&args[1], "def");
-        assert_eq!(args.get_flag("bar"), Some("xyz 123"));
-
-        // Unknown flags are validation errors.
-        assert!(parse_signature(r#"foo --quiz"#, signature).is_err());
-        // Duplicated flags are parsing errors.
-        assert!(parse_signature(r#"--foo bar --foo"#, signature).is_err());
-        assert!(parse_signature(r#"-f bar --foo"#, signature).is_err());
-
-        // "--" can be used to mark the end of flags. Everything after is considered a positional.
-        let args = parse_signature(r#"hello --bar baz -- --foo"#, signature).unwrap();
-        assert_eq!(args.len(), 2);
-        assert_eq!(&args[0], "hello");
-        assert_eq!(&args[1], "--foo");
-        assert_eq!(args.get_flag("bar"), Some("baz"));
-        assert!(!args.has_flag("foo"));
-    }
-
-    #[test]
-    fn raw_after() {
-        let signature = Signature {
-            positionals: (1, Some(1)),
-            raw_after: Some(0),
-            ..Signature::DEFAULT
-        };
-
-        // All quoting and escaping is treated literally in raw mode.
-        let args = parse_signature(r#"'\'"#, signature).unwrap();
-        assert_eq!(args.len(), 1);
-        assert_eq!(&args[0], "'\\'");
-        let args = parse_signature(r#"\''"#, signature).unwrap();
-        assert_eq!(args.len(), 1);
-        assert_eq!(&args[0], "\\''");
-
-        // Leading space is trimmed.
-        let args = parse_signature(r#"   %sh{foo}"#, signature).unwrap();
-        assert_eq!(args.len(), 1);
-        assert_eq!(&args[0], "%sh{foo}");
-
-        let signature = Signature {
-            positionals: (1, Some(2)),
-            raw_after: Some(1),
-            ..Signature::DEFAULT
-        };
-
-        let args = parse_signature("foo", signature).unwrap();
-        assert_eq!(args.len(), 1);
-        assert_eq!(&args[0], "foo");
-
-        // "--bar" is treated as a positional.
-        let args = parse_signature("foo --bar", signature).unwrap();
-        assert_eq!(args.len(), 2);
-        assert_eq!(&args[0], "foo");
-        assert_eq!(&args[1], "--bar");
-
-        let args = parse_signature("abc def ghi", signature).unwrap();
-        assert_eq!(args.len(), 2);
-        assert_eq!(&args[0], "abc");
-        assert_eq!(&args[1], "def ghi");
-
-        let args = parse_signature("rulers [20, 30]", signature).unwrap();
-        assert_eq!(args.len(), 2);
-        assert_eq!(&args[0], "rulers");
-        assert_eq!(&args[1], "[20, 30]");
-
-        let args =
-            parse_signature(r#"gutters ["diff"] ["diff", "diagnostics"]"#, signature).unwrap();
-        assert_eq!(args.len(), 2);
-        assert_eq!(&args[0], "gutters");
-        assert_eq!(&args[1], r#"["diff"] ["diff", "diagnostics"]"#);
-    }
-}
diff --git a/helix-term/src/handlers/completion/request 2.rs b/helix-term/src/handlers/completion/request 2.rs
deleted file mode 100644
index 3d2a158ea..000000000
--- a/helix-term/src/handlers/completion/request 2.rs	
+++ /dev/null
@@ -1,368 +0,0 @@
-use std::collections::{HashMap, HashSet};
-use std::sync::Arc;
-use std::time::Duration;
-
-use arc_swap::ArcSwap;
-use futures_util::Future;
-use helix_core::completion::CompletionProvider;
-use helix_core::syntax::LanguageServerFeature;
-use helix_event::{cancelable_future, TaskController, TaskHandle};
-use helix_lsp::lsp;
-use helix_lsp::lsp::{CompletionContext, CompletionTriggerKind};
-use helix_lsp::util::pos_to_lsp_pos;
-use helix_stdx::rope::RopeSliceExt;
-use helix_view::document::{Mode, SavePoint};
-use helix_view::handlers::completion::{CompletionEvent, ResponseContext};
-use helix_view::{Document, DocumentId, Editor, ViewId};
-use tokio::task::JoinSet;
-use tokio::time::{timeout_at, Instant};
-
-use crate::compositor::Compositor;
-use crate::config::Config;
-use crate::handlers::completion::item::CompletionResponse;
-use crate::handlers::completion::path::path_completion;
-use crate::handlers::completion::{
-    handle_response, replace_completions, show_completion, CompletionItems,
-};
-use crate::job::{dispatch, dispatch_blocking};
-use crate::ui;
-use crate::ui::editor::InsertEvent;
-
-#[derive(Debug, PartialEq, Eq, Clone, Copy)]
-pub(super) enum TriggerKind {
-    Auto,
-    TriggerChar,
-    Manual,
-}
-
-#[derive(Debug, Clone, Copy)]
-pub(super) struct Trigger {
-    pub(super) pos: usize,
-    pub(super) view: ViewId,
-    pub(super) doc: DocumentId,
-    pub(super) kind: TriggerKind,
-}
-
-#[derive(Debug)]
-pub struct CompletionHandler {
-    /// The currently active trigger which will cause a completion request after the timeout.
-    trigger: Option<Trigger>,
-    in_flight: Option<Trigger>,
-    task_controller: TaskController,
-    config: Arc<ArcSwap<Config>>,
-}
-
-impl CompletionHandler {
-    pub fn new(config: Arc<ArcSwap<Config>>) -> CompletionHandler {
-        Self {
-            config,
-            task_controller: TaskController::new(),
-            trigger: None,
-            in_flight: None,
-        }
-    }
-}
-
-impl helix_event::AsyncHook for CompletionHandler {
-    type Event = CompletionEvent;
-
-    fn handle_event(
-        &mut self,
-        event: Self::Event,
-        _old_timeout: Option<Instant>,
-    ) -> Option<Instant> {
-        if self.in_flight.is_some() && !self.task_controller.is_running() {
-            self.in_flight = None;
-        }
-        match event {
-            CompletionEvent::AutoTrigger {
-                cursor: trigger_pos,
-                doc,
-                view,
-            } => {
-                // Technically it shouldn't be possible to switch views/documents in insert mode
-                // but people may create weird keymaps/use the mouse so let's be extra careful.
-                if self
-                    .trigger
-                    .or(self.in_flight)
-                    .map_or(true, |trigger| trigger.doc != doc || trigger.view != view)
-                {
-                    self.trigger = Some(Trigger {
-                        pos: trigger_pos,
-                        view,
-                        doc,
-                        kind: TriggerKind::Auto,
-                    });
-                }
-            }
-            CompletionEvent::TriggerChar { cursor, doc, view } => {
-                // immediately request completions and drop all auto completion requests
-                self.task_controller.cancel();
-                self.trigger = Some(Trigger {
-                    pos: cursor,
-                    view,
-                    doc,
-                    kind: TriggerKind::TriggerChar,
-                });
-            }
-            CompletionEvent::ManualTrigger { cursor, doc, view } => {
-                // immediately request completions and drop all auto completion requests
-                self.trigger = Some(Trigger {
-                    pos: cursor,
-                    view,
-                    doc,
-                    kind: TriggerKind::Manual,
-                });
-                // stop debouncing immediately and request the completion
-                self.finish_debounce();
-                return None;
-            }
-            CompletionEvent::Cancel => {
-                self.trigger = None;
-                self.task_controller.cancel();
-            }
-            CompletionEvent::DeleteText { cursor } => {
-                // if we deleted the original trigger, abort the completion
-                if matches!(self.trigger.or(self.in_flight), Some(Trigger{ pos, .. }) if cursor < pos)
-                {
-                    self.trigger = None;
-                    self.task_controller.cancel();
-                }
-            }
-        }
-        self.trigger.map(|trigger| {
-            // if the current request was closed forget about it
-            // otherwise immediately restart the completion request
-            let timeout = if trigger.kind == TriggerKind::Auto {
-                self.config.load().editor.completion_timeout
-            } else {
-                // we want almost instant completions for trigger chars
-                // and restarting completion requests. The small timeout here mainly
-                // serves to better handle cases where the completion handler
-                // may fall behind (so multiple events in the channel) and macros
-                Duration::from_millis(5)
-            };
-            Instant::now() + timeout
-        })
-    }
-
-    fn finish_debounce(&mut self) {
-        let trigger = self.trigger.take().expect("debounce always has a trigger");
-        self.in_flight = Some(trigger);
-        let handle = self.task_controller.restart();
-        dispatch_blocking(move |editor, compositor| {
-            request_completions(trigger, handle, editor, compositor)
-        });
-    }
-}
-
-fn request_completions(
-    mut trigger: Trigger,
-    handle: TaskHandle,
-    editor: &mut Editor,
-    compositor: &mut Compositor,
-) {
-    let (view, doc) = current_ref!(editor);
-
-    if compositor
-        .find::<ui::EditorView>()
-        .unwrap()
-        .completion
-        .is_some()
-        || editor.mode != Mode::Insert
-    {
-        return;
-    }
-
-    let text = doc.text();
-    let cursor = doc.selection(view.id).primary().cursor(text.slice(..));
-    if trigger.view != view.id || trigger.doc != doc.id() || cursor < trigger.pos {
-        return;
-    }
-    // This looks odd... Why are we not using the trigger position from the `trigger` here? Won't
-    // that mean that the trigger char doesn't get send to the language server if we type fast
-    // enough? Yes that is true but it's not actually a problem. The language server will resolve
-    // the completion to the identifier anyway (in fact sending the later position is necessary to
-    // get the right results from language servers that provide incomplete completion list). We
-    // rely on the trigger offset and primary cursor matching for multi-cursor completions so this
-    // is definitely necessary from our side too.
-    trigger.pos = cursor;
-    let doc = doc_mut!(editor, &doc.id());
-    let savepoint = doc.savepoint(view);
-    let text = doc.text();
-    let trigger_text = text.slice(..cursor);
-
-    let mut seen_language_servers = HashSet::new();
-    let language_servers: Vec<_> = doc
-        .language_servers_with_feature(LanguageServerFeature::Completion)
-        .filter(|ls| seen_language_servers.insert(ls.id()))
-        .collect();
-    let mut requests = JoinSet::new();
-    for (priority, ls) in language_servers.iter().enumerate() {
-        let context = if trigger.kind == TriggerKind::Manual {
-            lsp::CompletionContext {
-                trigger_kind: lsp::CompletionTriggerKind::INVOKED,
-                trigger_character: None,
-            }
-        } else {
-            let trigger_char =
-                ls.capabilities()
-                    .completion_provider
-                    .as_ref()
-                    .and_then(|provider| {
-                        provider
-                            .trigger_characters
-                            .as_deref()?
-                            .iter()
-                            .find(|&trigger| trigger_text.ends_with(trigger))
-                    });
-
-            if trigger_char.is_some() {
-                lsp::CompletionContext {
-                    trigger_kind: lsp::CompletionTriggerKind::TRIGGER_CHARACTER,
-                    trigger_character: trigger_char.cloned(),
-                }
-            } else {
-                lsp::CompletionContext {
-                    trigger_kind: lsp::CompletionTriggerKind::INVOKED,
-                    trigger_character: None,
-                }
-            }
-        };
-        requests.spawn(request_completions_from_language_server(
-            ls,
-            doc,
-            view.id,
-            context,
-            -(priority as i8),
-            savepoint.clone(),
-        ));
-    }
-    if let Some(path_completion_request) = path_completion(
-        doc.selection(view.id).clone(),
-        doc,
-        handle.clone(),
-        savepoint,
-    ) {
-        requests.spawn_blocking(path_completion_request);
-    }
-
-    let ui = compositor.find::<ui::EditorView>().unwrap();
-    ui.last_insert.1.push(InsertEvent::RequestCompletion);
-    let handle_ = handle.clone();
-    let request_completions = async move {
-        let mut context = HashMap::new();
-        let Some(mut response) = handle_response(&mut requests, false).await else {
-            return;
-        };
-
-        let mut items: Vec<_> = Vec::new();
-        response.take_items(&mut items);
-        context.insert(response.provider, response.context);
-        let deadline = Instant::now() + Duration::from_millis(100);
-        loop {
-            let Some(mut response) = timeout_at(deadline, handle_response(&mut requests, false))
-                .await
-                .ok()
-                .flatten()
-            else {
-                break;
-            };
-            response.take_items(&mut items);
-            context.insert(response.provider, response.context);
-        }
-        dispatch(move |editor, compositor| {
-            show_completion(editor, compositor, items, context, trigger)
-        })
-        .await;
-        if !requests.is_empty() {
-            replace_completions(handle_, requests, false).await;
-        }
-    };
-    tokio::spawn(cancelable_future(request_completions, handle));
-}
-
-fn request_completions_from_language_server(
-    ls: &helix_lsp::Client,
-    doc: &Document,
-    view: ViewId,
-    context: lsp::CompletionContext,
-    priority: i8,
-    savepoint: Arc<SavePoint>,
-) -> impl Future<Output = CompletionResponse> {
-    let provider = ls.id();
-    let offset_encoding = ls.offset_encoding();
-    let text = doc.text();
-    let cursor = doc.selection(view).primary().cursor(text.slice(..));
-    let pos = pos_to_lsp_pos(text, cursor, offset_encoding);
-    let doc_id = doc.identifier();
-
-    // it's important that this is before the async block (and that this is not an async function)
-    // to ensure the request is dispatched right away before any new edit notifications
-    let completion_response = ls.completion(doc_id, pos, None, context).unwrap();
-    async move {
-        let response: Option<lsp::CompletionResponse> = completion_response
-            .await
-            .and_then(|json| serde_json::from_value(json).map_err(helix_lsp::Error::Parse))
-            .inspect_err(|err| log::error!("completion request failed: {err}"))
-            .ok()
-            .flatten();
-        let (mut items, is_incomplete) = match response {
-            Some(lsp::CompletionResponse::Array(items)) => (items, false),
-            Some(lsp::CompletionResponse::List(lsp::CompletionList {
-                is_incomplete,
-                items,
-            })) => (items, is_incomplete),
-            None => (Vec::new(), false),
-        };
-        items.sort_by(|item1, item2| {
-            let sort_text1 = item1.sort_text.as_deref().unwrap_or(&item1.label);
-            let sort_text2 = item2.sort_text.as_deref().unwrap_or(&item2.label);
-            sort_text1.cmp(sort_text2)
-        });
-        CompletionResponse {
-            items: CompletionItems::Lsp(items),
-            context: ResponseContext {
-                is_incomplete,
-                priority,
-                savepoint,
-            },
-            provider: CompletionProvider::Lsp(provider),
-        }
-    }
-}
-
-pub fn request_incomplete_completion_list(editor: &mut Editor, handle: TaskHandle) {
-    let handler = &mut editor.handlers.completions;
-    let mut requests = JoinSet::new();
-    let mut savepoint = None;
-    for (&provider, context) in &handler.active_completions {
-        if !context.is_incomplete {
-            continue;
-        }
-        let CompletionProvider::Lsp(ls_id) = provider else {
-            log::error!("non-lsp incomplete completion lists");
-            continue;
-        };
-        let Some(ls) = editor.language_servers.get_by_id(ls_id) else {
-            continue;
-        };
-        let (view, doc) = current!(editor);
-        let savepoint = savepoint.get_or_insert_with(|| doc.savepoint(view)).clone();
-        let request = request_completions_from_language_server(
-            ls,
-            doc,
-            view.id,
-            CompletionContext {
-                trigger_kind: CompletionTriggerKind::TRIGGER_FOR_INCOMPLETE_COMPLETIONS,
-                trigger_character: None,
-            },
-            context.priority,
-            savepoint,
-        );
-        requests.spawn(request);
-    }
-    if !requests.is_empty() {
-        tokio::spawn(replace_completions(handle, requests, true));
-    }
-}
diff --git a/helix-term/src/ui/editor.rs b/helix-term/src/ui/editor.rs
index 41cae8a78..9343d55d4 100644
--- a/helix-term/src/ui/editor.rs
+++ b/helix-term/src/ui/editor.rs
@@ -19,13 +19,13 @@
     movement::Direction,
     syntax::{self, OverlayHighlights},
     text_annotations::TextAnnotations,
-    unicode::{segmentation::UnicodeSegmentation, width::UnicodeWidthStr},
+    unicode::width::UnicodeWidthStr,
     visual_offset_from_block, Change, Position, Range, Selection, Transaction,
 };
 use helix_view::{
     annotations::diagnostics::DiagnosticFilter,
-    document::{Mode, SavePoint, SCRATCH_BUFFER_NAME},
-    editor::{BufferLine, CompleteAction, CursorShapeConfig},
+    document::{Mode, SCRATCH_BUFFER_NAME},
+    editor::{CompleteAction, CursorShapeConfig},
     graphics::{Color, CursorKind, Modifier, Rect, Style},
     input::{KeyEvent, MouseButton, MouseEvent, MouseEventKind},
     keyboard::{KeyCode, KeyModifiers},
@@ -57,21 +57,6 @@ pub enum InsertEvent {
     RequestCompletion,
 }
 
-#[derive(Debug, Clone)]
-pub struct BufferTab {
-    active: bool,
-    text: String,
-    width: u16,
-    x: i32,
-    style: Style,
-}
-
-impl Default for EditorView {
-    fn default() -> Self {
-        Self::new(Keymaps::default())
-    }
-}
-
 impl EditorView {
     pub fn new(keymaps: Keymaps) -> Self {
         Self {
@@ -575,7 +560,15 @@ pub fn tabstop_highlights(doc: &Document, theme: &Theme) -> Option<OverlayHighli
 
     /// Render bufferline at the top
     pub fn render_bufferline(editor: &Editor, viewport: Rect, surface: &mut Surface) {
-        // Define styles
+        let scratch = PathBuf::from(SCRATCH_BUFFER_NAME); // default filename to use for scratch buffer
+        surface.clear_with(
+            viewport,
+            editor
+                .theme
+                .try_get("ui.bufferline.background")
+                .unwrap_or_else(|| editor.theme.get("ui.statusline")),
+        );
+
         let bufferline_active = editor
             .theme
             .try_get("ui.bufferline.active")
@@ -586,13 +579,9 @@ pub fn render_bufferline(editor: &Editor, viewport: Rect, surface: &mut Surface)
             .try_get("ui.bufferline")
             .unwrap_or_else(|| editor.theme.get("ui.statusline.inactive"));
 
-        let mut x = viewport.x as i32;
+        let mut x = viewport.x;
         let current_doc = view!(editor).doc;
 
-        // Gather info on buffertabs
-        let mut buffertabs = Vec::new();
-
-        let scratch = PathBuf::from(SCRATCH_BUFFER_NAME); // default filename to use for scratch buffer
         for doc in editor.documents() {
             let fname = doc
                 .path()
@@ -602,121 +591,23 @@ pub fn render_bufferline(editor: &Editor, viewport: Rect, surface: &mut Surface)
                 .to_str()
                 .unwrap_or_default();
 
-            let active = current_doc == doc.id();
-
-            let style = if active {
+            let style = if current_doc == doc.id() {
                 bufferline_active
             } else {
                 bufferline_inactive
             };
 
             let text = format!(" {}{} ", fname, if doc.is_modified() { "[+]" } else { "" });
-            let text_width = text.grapheme_indices(true).count();
-
-            buffertabs.push(BufferTab {
-                active,
-                text,
-                width: text_width as _,
-                x,
-                style,
-            });
-            x = x.saturating_add(text_width as _);
-        }
-
-        surface.clear_with(
-            viewport,
-            editor
-                .theme
-                .try_get("ui.bufferline.background")
-                .unwrap_or_else(|| editor.theme.get("ui.statusline")),
-        );
-
-        // Scroll the tabs correctly
-        // The idea is to align the center of the buffer tab
-        // as close to the center of the viewport as possible
-        let viewport_center = (viewport.width as f64 / 2.).floor() as i32 + viewport.x as i32;
-
-        let active_buffertab = buffertabs.iter().find(|tab| tab.active).unwrap();
-
-        let active_buffertab_center =
-            (active_buffertab.width as f64 / 2.).floor() as i32 + active_buffertab.x;
-
-        let right_of_center = active_buffertab_center - viewport_center;
+            let used_width = viewport.x.saturating_sub(x);
+            let rem_width = surface.area.width.saturating_sub(used_width);
 
-        // If the active tab falls on the right, we have to move it left by some amount.
-        // For easthetics, I've chosen to have the rightmost tab not to scroll further left
-        // than needed, clamping it to the right of the viewport.
-
-        // Get the full width of the bufferline
-        let rightmost = buffertabs.last().unwrap();
-        let full_width = rightmost.x + rightmost.width as i32;
-
-        // The maximum possible displacement is amount of overflow on the right
-        // of the viewport. If no overflow, maximum displacement is 0.
-        let max_displacement = (full_width - viewport.width as i32).max(0);
-
-        // This part clamps the scrolling of the bufferline to the right of the viewport.
-        let displacement = right_of_center.clamp(0, max_displacement);
-
-        // If there's any displacement, there's underflow of the bufferline.
-        let mark_underflow = displacement > 0;
-
-        // If the displacement is not at max, there's overflow of the bufferline.
-        let mark_overflow = displacement < max_displacement;
-
-        for tab in buffertabs.iter_mut() {
-            tab.x = tab.x.saturating_sub(displacement);
-        }
+            x = surface
+                .set_stringn(x, viewport.y, text, rem_width as usize, style)
+                .0;
 
-        // Itterate over buffertabs, skip or slice them if left off screen, stop if right of screen.
-        for tab in buffertabs.iter_mut() {
-            if tab.x < viewport.x as i32 {
-                if tab.x + tab.width as i32 > viewport.x as i32 {
-                    // Draw on screen portion
-                    let new_width = tab.width as i32 + tab.x;
-
-                    tab.text = tab
-                        .text
-                        .graphemes(true)
-                        .skip((tab.width as i32 - new_width) as usize)
-                        .collect();
-
-                    tab.width -= new_width as u16;
-                    tab.x = viewport.x as _;
-                } else {
-                    // Skip tabs completely of screen
-                    continue;
-                }
-            }
-            if tab.x > viewport.right() as i32 {
-                // Stop when off screen to the right
+            if x >= surface.area.right() {
                 break;
             }
-
-            // Actually put the string on the screen
-            surface
-                .set_stringn(
-                    tab.x as _,
-                    viewport.y,
-                    tab.text.clone(),
-                    (viewport.right() as usize).saturating_sub(tab.x as _),
-                    tab.style,
-                )
-                .0;
-        }
-
-        // Add under and overflow markers.
-        let markers = editor
-            .theme
-            .try_get("ui.bufferline.marker")
-            .unwrap_or_else(|| editor.theme.get("ui.bufferline"));
-
-        if mark_underflow {
-            surface.set_string(viewport.left(), viewport.top(), " < ", markers);
-        }
-
-        if mark_overflow {
-            surface.set_string(viewport.right() - 3, viewport.top(), " > ", markers);
         }
     }
 
@@ -1603,6 +1494,7 @@ fn render(&mut self, area: Rect, surface: &mut Surface, cx: &mut Context) {
         let config = cx.editor.config();
 
         // check if bufferline should be rendered
+        use helix_view::editor::BufferLine;
         let use_bufferline = match config.bufferline {
             BufferLine::Always => true,
             BufferLine::Multiple if cx.editor.documents.len() > 1 => true,
diff --git a/helix-term/tests/test/command_line 2.rs b/helix-term/tests/test/command_line 2.rs
deleted file mode 100644
index 0e2270060..000000000
--- a/helix-term/tests/test/command_line 2.rs	
+++ /dev/null
@@ -1,103 +0,0 @@
-use super::*;
-
-use helix_core::diagnostic::Severity;
-
-#[tokio::test(flavor = "multi_thread")]
-async fn history_completion() -> anyhow::Result<()> {
-    test_key_sequence(
-        &mut AppBuilder::new().build()?,
-        Some(":asdf<ret>:theme d<C-n><tab>"),
-        Some(&|app| {
-            assert!(!app.editor.is_err());
-        }),
-        false,
-    )
-    .await?;
-
-    Ok(())
-}
-
-async fn test_statusline(
-    line: &str,
-    expected_status: &str,
-    expected_severity: Severity,
-) -> anyhow::Result<()> {
-    test_key_sequence(
-        &mut AppBuilder::new().build()?,
-        Some(&format!("{line}<ret>")),
-        Some(&|app| {
-            let (status, &severity) = app.editor.get_status().unwrap();
-            assert_eq!(
-                severity, expected_severity,
-                "'{line}' printed {severity:?}: {status}"
-            );
-            assert_eq!(status.as_ref(), expected_status);
-        }),
-        false,
-    )
-    .await
-}
-
-#[tokio::test(flavor = "multi_thread")]
-async fn variable_expansion() -> anyhow::Result<()> {
-    test_statusline(r#":echo %{cursor_line}"#, "1", Severity::Info).await?;
-    // Double quotes can be used with expansions:
-    test_statusline(
-        r#":echo "line%{cursor_line}line""#,
-        "line1line",
-        Severity::Info,
-    )
-    .await?;
-    // Within double quotes you can escape the percent token for an expansion by doubling it.
-    test_statusline(
-        r#":echo "%%{cursor_line}""#,
-        "%{cursor_line}",
-        Severity::Info,
-    )
-    .await?;
-
-    Ok(())
-}
-
-#[tokio::test(flavor = "multi_thread")]
-async fn unicode_expansion() -> anyhow::Result<()> {
-    test_statusline(r#":echo %u{20}"#, " ", Severity::Info).await?;
-    test_statusline(r#":echo %u{0020}"#, " ", Severity::Info).await?;
-    test_statusline(r#":echo %u{25CF}"#, "●", Severity::Info).await?;
-    // Not a valid Unicode codepoint:
-    test_statusline(
-        r#":echo %u{deadbeef}"#,
-        "'echo': could not interpret 'deadbeef' as a Unicode character code",
-        Severity::Error,
-    )
-    .await?;
-
-    Ok(())
-}
-
-#[cfg(unix)]
-#[tokio::test(flavor = "multi_thread")]
-async fn shell_expansion() -> anyhow::Result<()> {
-    test_statusline(
-        r#":echo %sh{echo "hello world"}"#,
-        "hello world",
-        Severity::Info,
-    )
-    .await?;
-
-    // Shell expansion is recursive.
-    test_statusline(":echo %sh{echo '%{cursor_line}'}", "1", Severity::Info).await?;
-
-    Ok(())
-}
-
-#[tokio::test(flavor = "multi_thread")]
-async fn percent_escaping() -> anyhow::Result<()> {
-    test_statusline(
-        r#":sh echo hello 10%"#,
-        "'run-shell-command': '%' was not properly escaped. Please use '%%'",
-        Severity::Error,
-    )
-    .await?;
-    Ok(())
-}
diff --git a/helix-view/src/expansion 2.rs b/helix-view/src/expansion 2.rs
deleted file mode 100644
index 96a71b8e5..000000000
--- a/helix-view/src/expansion 2.rs	
+++ /dev/null
@@ -1,219 +0,0 @@
-use std::borrow::Cow;
-
-use helix_core::command_line::{ExpansionKind, Token, TokenKind, Tokenizer};
-
-use anyhow::{anyhow, bail, Result};
-
-use crate::Editor;
-
-/// Variables that can be expanded in the command mode (`:`) via the expansion syntax.
-///
-/// For example `%{cursor_line}`.
-//
-// To add a new variable follow these steps:
-//
-// * Add the new enum member to `Variable` below.
-// * Add an item to the `VARIANTS` constant - this enables completion.
-// * Add a branch in `Variable::as_str`, converting the name from TitleCase to snake_case.
-// * Add a branch in `Variable::from_name` with the reverse association.
-// * Add a branch in the `expand_variable` function to read the value from the editor.
-// * Add the new variable to the documentation in `book/src/command-line.md`.
-#[derive(Debug, Clone, Copy, PartialEq, Eq)]
-pub enum Variable {
-    /// The one-indexed line number of the primary cursor in the currently focused document.
-    CursorLine,
-    /// The one-indexed column number of the primary cursor in the currently focused document.
-    ///
-    /// Note that this is the count of grapheme clusters from the start of the line (regardless of
-    /// softwrap) - the same as the `position` element in the statusline.
-    CursorColumn,
-    /// The display name of the currently focused document.
-    ///
-    /// This corresponds to `crate::Document::display_name`.
-    BufferName,
-    /// A string containing the line-ending of the currently focused document.
-    LineEnding,
-}
-
-impl Variable {
-    pub const VARIANTS: &'static [Self] = &[
-        Self::CursorLine,
-        Self::CursorColumn,
-        Self::BufferName,
-        Self::LineEnding,
-    ];
-
-    pub const fn as_str(&self) -> &'static str {
-        match self {
-            Self::CursorLine => "cursor_line",
-            Self::CursorColumn => "cursor_column",
-            Self::BufferName => "buffer_name",
-            Self::LineEnding => "line_ending",
-        }
-    }
-
-    pub fn from_name(s: &str) -> Option<Self> {
-        match s {
-            "cursor_line" => Some(Self::CursorLine),
-            "cursor_column" => Some(Self::CursorColumn),
-            "buffer_name" => Some(Self::BufferName),
-            "line_ending" => Some(Self::LineEnding),
-            _ => None,
-        }
-    }
-}
-
-/// Expands the given command line token.
-///
-/// Note that the lifetime of the expanded variable is only bound to the input token and not the
-/// `Editor`. See `expand_variable` below for more discussion of lifetimes.
-pub fn expand<'a>(editor: &Editor, token: Token<'a>) -> Result<Cow<'a, str>> {
-    // Note: see the `TokenKind` documentation for more details on how each branch should expand.
-    match token.kind {
-        TokenKind::Unquoted | TokenKind::Quoted(_) => Ok(token.content),
-        TokenKind::Expansion(ExpansionKind::Variable) => {
-            let var = Variable::from_name(&token.content)
-                .ok_or_else(|| anyhow!("unknown variable '{}'", token.content))?;
-
-            expand_variable(editor, var)
-        }
-        TokenKind::Expansion(ExpansionKind::Unicode) => {
-            if let Some(ch) = u32::from_str_radix(token.content.as_ref(), 16)
-                .ok()
-                .and_then(char::from_u32)
-            {
-                Ok(Cow::Owned(ch.to_string()))
-            } else {
-                Err(anyhow!(
-                    "could not interpret '{}' as a Unicode character code",
-                    token.content
-                ))
-            }
-        }
-        TokenKind::Expand => expand_inner(editor, token.content),
-        TokenKind::Expansion(ExpansionKind::Shell) => expand_shell(editor, token.content),
-        // Note: see the docs for this variant.
-        TokenKind::ExpansionKind => unreachable!(
-            "expansion name tokens cannot be emitted when command line validation is enabled"
-        ),
-    }
-}
-
-/// Expand a shell command.
-pub fn expand_shell<'a>(editor: &Editor, content: Cow<'a, str>) -> Result<Cow<'a, str>> {
-    use std::process::{Command, Stdio};
-
-    // Recursively expand the expansion's content before executing the shell command.
-    let content = expand_inner(editor, content)?;
-
-    let config = editor.config();
-    let shell = &config.shell;
-    let mut process = Command::new(&shell[0]);
-    process
-        .args(&shell[1..])
-        .arg(content.as_ref())
-        .stdin(Stdio::null())
-        .stdout(Stdio::piped())
-        .stderr(Stdio::piped());
-
-    // TODO: there is no protection here against a shell command taking a long time.
-    // Ideally you should be able to hit `<ret>` in command mode and then be able to
-    // cancel the invocation (for example with `<C-c>`) if it takes longer than you'd
-    // like.
-    let output = match process.spawn() {
-        Ok(process) => process.wait_with_output()?,
-        Err(err) => {
-            bail!("Failed to start shell: {err}");
-        }
-    };
-
-    let mut text = String::from_utf8_lossy(&output.stdout).into_owned();
-
-    if !output.stderr.is_empty() {
-        log::warn!(
-            "Shell expansion command `{content}` failed: {}",
-            String::from_utf8_lossy(&output.stderr)
-        );
-    }
-
-    // Trim exactly one trailing line ending if it exists.
-    if text.ends_with('\n') {
-        text.pop();
-        if text.ends_with('\r') {
-            text.pop();
-        }
-    }
-
-    Ok(Cow::Owned(text))
-}
-
-/// Expand a token's contents recursively.
-fn expand_inner<'a>(editor: &Editor, content: Cow<'a, str>) -> Result<Cow<'a, str>> {
-    let mut escaped = String::new();
-    let mut start = 0;
-
-    while let Some(offset) = content[start..].find('%') {
-        let idx = start + offset;
-        if content.as_bytes().get(idx + '%'.len_utf8()).copied() == Some(b'%') {
-            // Treat two percents in a row as an escaped percent.
-            escaped.push_str(&content[start..=idx]);
-            // Skip over both percents.
-            start = idx + ('%'.len_utf8() * 2);
-        } else {
-            // Otherwise interpret the percent as an expansion. Push up to (but not
-            // including) the percent token.
-            escaped.push_str(&content[start..idx]);
-            // Then parse the expansion,
-            let mut tokenizer = Tokenizer::new(&content[idx..], true);
-            let token = tokenizer
-                .parse_percent_token()
-                .unwrap()
-                .map_err(|err| anyhow!("{err}"))?;
-            // expand it (this is the recursive part),
-            let expanded = expand(editor, token)?;
-            escaped.push_str(expanded.as_ref());
-            // and move forward to the end of the expansion.
-            start = idx + tokenizer.pos();
-        }
-    }
-
-    if escaped.is_empty() {
-        Ok(content)
-    } else {
-        escaped.push_str(&content[start..]);
-        Ok(Cow::Owned(escaped))
-    }
-}
-
-// Note: the lifetime of the expanded variable (the `Cow`) must not be tied to the lifetime of
-// the borrow of `Editor`. That would prevent commands from mutating the `Editor` until the
-// command consumed or cloned all arguments - this is poor ergonomics. A sensible thing for this
-// function to return then, instead, would normally be a `String`. We can return some statically
-// known strings like the scratch buffer name or line ending strings though, so this function
-// returns a `Cow<'static, str>` instead.
-fn expand_variable(editor: &Editor, variable: Variable) -> Result<Cow<'static, str>> {
-    let (view, doc) = current_ref!(editor);
-    let text = doc.text().slice(..);
-
-    match variable {
-        Variable::CursorLine => {
-            let cursor_line = doc.selection(view.id).primary().cursor_line(text);
-            Ok(Cow::Owned((cursor_line + 1).to_string()))
-        }
-        Variable::CursorColumn => {
-            let cursor = doc.selection(view.id).primary().cursor(text);
-            let position = helix_core::coords_at_pos(text, cursor);
-            Ok(Cow::Owned((position.col + 1).to_string()))
-        }
-        Variable::BufferName => {
-            // Note: usually we would use `Document::display_name` but we can statically borrow
-            // the scratch buffer name by partially reimplementing `display_name`.
-            if let Some(path) = doc.relative_path() {
-                Ok(Cow::Owned(path.to_string_lossy().into_owned()))
-            } else {
-                Ok(Cow::Borrowed(crate::document::SCRATCH_BUFFER_NAME))
-            }
-        }
-        Variable::LineEnding => Ok(Cow::Borrowed(doc.line_ending.as_str())),
-    }
-}
diff --git a/helix-view/src/handlers/completion 2.rs b/helix-view/src/handlers/completion 2.rs
deleted file mode 100644
index db3f0b26b..000000000
--- a/helix-view/src/handlers/completion 2.rs	
+++ /dev/null
@@ -1,64 +0,0 @@
-use std::{collections::HashMap, sync::Arc};
-
-use helix_core::completion::CompletionProvider;
-use helix_event::{send_blocking, TaskController};
-
-use crate::{document::SavePoint, DocumentId, ViewId};
-
-use tokio::sync::mpsc::Sender;
-
-pub struct CompletionHandler {
-    event_tx: Sender<CompletionEvent>,
-    pub active_completions: HashMap<CompletionProvider, ResponseContext>,
-    pub request_controller: TaskController,
-}
-
-impl CompletionHandler {
-    pub fn new(event_tx: Sender<CompletionEvent>) -> Self {
-        Self {
-            event_tx,
-            active_completions: HashMap::new(),
-            request_controller: TaskController::new(),
-        }
-    }
-
-    pub fn event(&self, event: CompletionEvent) {
-        send_blocking(&self.event_tx, event);
-    }
-}
-
-pub struct ResponseContext {
-    /// Whether the completion response is marked as "incomplete."
-    ///
-    /// This is used by LSP. When completions are "incomplete" and you continue typing, the
-    /// completions should be recomputed by the server instead of filtered.
-    pub is_incomplete: bool,
-    pub priority: i8,
-    pub savepoint: Arc<SavePoint>,
-}
-
-pub enum CompletionEvent {
-    /// Auto completion was triggered by typing a word char
-    AutoTrigger {
-        cursor: usize,
-        doc: DocumentId,
-        view: ViewId,
-    },
-    /// Auto completion was triggered by typing a trigger char
-    /// specified by the LSP
-    TriggerChar {
-        cursor: usize,
-        doc: DocumentId,
-        view: ViewId,
-    },
-    /// A completion was manually requested (c-x)
-    ManualTrigger {
-        cursor: usize,
-        doc: DocumentId,
-        view: ViewId,
-    },
-    /// Some text was deleted and the cursor is now at `pos`
-    DeleteText { cursor: usize },
-    /// Invalidate the current auto completion trigger
-    Cancel,
-}
diff --git a/runtime/queries/c-sharp/tags 2.scm b/runtime/queries/c-sharp/tags 2.scm
deleted file mode 100644
index ffb2dd239..000000000
--- a/runtime/queries/c-sharp/tags 2.scm	
+++ /dev/null
@@ -1,23 +0,0 @@
-(class_declaration name: (identifier) @name) @definition.class
-
-(class_declaration (base_list (_) @name)) @reference.class
-
-(interface_declaration name: (identifier) @name) @definition.interface
-
-(interface_declaration (base_list (_) @name)) @reference.interface
-
-(method_declaration name: (identifier) @name) @definition.method
-
-(object_creation_expression type: (identifier) @name) @reference.class
-
-(type_parameter_constraints_clause (identifier) @name) @reference.class
-
-(type_parameter_constraint (type type: (identifier) @name)) @reference.class
-
-(variable_declaration type: (identifier) @name) @reference.class
-
-(invocation_expression function: (member_access_expression name: (identifier) @name)) @reference.send
-
-(namespace_declaration name: (identifier) @name) @definition.module
-
-(namespace_declaration name: (identifier) @name) @module
diff --git a/runtime/queries/kotlin/indents 2.scm b/runtime/queries/kotlin/indents 2.scm
deleted file mode 100644
index 6fe73aec3..000000000
--- a/runtime/queries/kotlin/indents 2.scm	
+++ /dev/null
@@ -1,44 +0,0 @@
-[
-  (class_body)
-  (enum_class_body)
-  (lambda_literal)
-
-  ; _block is hidden in the grammar, so list all public wrappers explicitly.
-  (function_body)
-  (anonymous_initializer)
-  (control_structure_body)
-  (secondary_constructor)
-  (try_expression)
-  (catch_block)
-  (finally_block)
-
-  (property_declaration)
-  (assignment)
-
-  (when_expression)
-  (call_expression)
-  (if_expression)
-
-  ; Binary expressions
-  (multiplicative_expression)
-  (additive_expression)
-  (range_expression)
-  (infix_expression)
-  (elvis_expression)
-  (check_expression)
-  (comparison_expression)
-  (equality_expression)
-  (comparison_expression)
-  (equality_expression)
-  (conjunction_expression)
-  (disjunction_expression)
-
-  (call_suffix)
-  (function_value_parameters)
-] @indent
-
-[
-  "}"
-  ")"
-  "]"
-] @outdent
diff --git a/runtime/queries/kotlin/textobjects 2.scm b/runtime/queries/kotlin/textobjects 2.scm
deleted file mode 100644
index 46bb26b2e..000000000
--- a/runtime/queries/kotlin/textobjects 2.scm	
+++ /dev/null
@@ -1,42 +0,0 @@
-(function_declaration
-  (function_body)? @function.inside) @function.around
-
-; Unlike function_body above, the constructor body is does not have its own
-; symbol in the current grammar.
-(secondary_constructor) @function.around
-
-(class_declaration
-  (class_body)? @class.inside) @class.around
-
-(class_declaration
-  (enum_class_body) @class.inside) @class.around
-
-[
-  (line_comment)
-  (multiline_comment)
-] @comment.inside
-
-(line_comment)+ @comment.around
-
-(multiline_comment) @comment.around
-
-(enum_entry) @entry.around
-(lambda_literal) @entry.around
-(property_declaration) @entry.around
-(object_declaration) @entry.around
-(assignment) @entry.around
-
-; TODO: This doesn't work with annotations yet, but fixing it without breaking
-; the case of multiple parameters is non-trivial.
-(function_value_parameters
-  ((_) @parameter.inside . ","? @parameter.around) @parameter.around)
-
-; secondary constructor uses function_value_parameters above
-(primary_constructor
-  ((_)@parameter.inside . ","? @parameter.around) @parameter.around)
-
-(function_type_parameters
-  ((_)@parameter.inside . ","? @parameter.around) @parameter.around)
-
-(value_arguments
-  ((_)@parameter.inside . ","? @parameter.around) @parameter.around)
